import os
import json
import json
import requests
import streamlit as st
from dotenv import load_dotenv

# API í‚¤ ë¡œë“œ (Streamlit Cloudì™€ ë¡œì»¬ í™˜ê²½ ëª¨ë‘ ì§€ì›)
# Streamlit Cloudì—ì„œëŠ” st.secretsë¥¼ ì‚¬ìš©, ë¡œì»¬ì—ì„œëŠ” .env íŒŒì¼ ì‚¬ìš©
try:
    # Streamlit Cloudì˜ secretsì—ì„œ ë¨¼ì € ì‹œë„
    if hasattr(st, 'secrets') and 'GOOGLE_API_KEY' in st.secrets:
        API_KEY = st.secrets['GOOGLE_API_KEY']
    else:
        # ë¡œì»¬ í™˜ê²½: .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
        env_paths = []
        try:
            # í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬
            env_paths.append(os.path.join(os.path.dirname(os.path.abspath(__file__)), '.env'))
        except:
            pass

        # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬
        env_paths.append('.env')
        env_paths.append(os.path.join(os.getcwd(), '.env'))

        # .env íŒŒì¼ ì°¾ì•„ì„œ ë¡œë“œ
        loaded = False
        for env_path in env_paths:
            if os.path.exists(env_path):
                load_dotenv(env_path, override=True)
                loaded = True
                break

        # ëª¨ë“  ê²½ë¡œì—ì„œ ì°¾ì§€ ëª»í•œ ê²½ìš° ê¸°ë³¸ ë¡œë“œ ì‹œë„
        if not loaded:
            load_dotenv()
        
        API_KEY = os.getenv("GOOGLE_API_KEY")
except:
    # í´ë°±: í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
    API_KEY = os.getenv("GOOGLE_API_KEY")

# ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
def get_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    available_models = []
    
    # v1beta APIë¡œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹œë„
    for api_version in ["v1beta", "v1"]:
        try:
            list_url = f"https://generativelanguage.googleapis.com/{api_version}/models?key={API_KEY}"
            response = requests.get(list_url, timeout=10)
            if response.status_code == 200:
                data = response.json()
                if "models" in data:
                    for model in data["models"]:
                        model_name = model.get("name", "")
                        supported_methods = model.get("supportedGenerationMethods", [])
                        # streamGenerateContentë¥¼ ì§€ì›í•˜ëŠ” ëª¨ë¸ë§Œ ì¶”ê°€
                        if "streamGenerateContent" in supported_methods:
                            # ëª¨ë¸ ì´ë¦„ì—ì„œ ë²„ì „ ì¶”ì¶œ (ì˜ˆ: "models/gemini-pro" -> "gemini-pro")
                            if "/" in model_name:
                                short_name = model_name.split("/")[-1]
                                available_models.append((api_version, short_name))
                    if available_models:
                        break
        except:
            continue
    
    # ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜¤ì§€ ëª»í•œ ê²½ìš° ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©
    if not available_models:
        available_models = [
            ("v1beta", "gemini-pro"),
            ("v1", "gemini-pro"),
        ]
    
    return available_models

# ì„¸ì…˜ ìƒíƒœì— ëª¨ë¸ ëª©ë¡ ì €ì¥ (í•œ ë²ˆë§Œ ì¡°íšŒ)
if 'available_models' not in st.session_state:
    st.session_state.available_models = get_available_models()

API_CONFIGS = st.session_state.available_models

# ê¸°ë³¸ ì„¤ì •
if API_CONFIGS:
    API_VERSION = API_CONFIGS[0][0]
    MODEL_NAME = API_CONFIGS[0][1]
else:
    # í´ë°±
    API_VERSION = "v1beta"
    MODEL_NAME = "gemini-pro"

st.set_page_config(page_title="Gemini ë¬¸ë²• êµì • ì±—ë´‡", page_icon="ğŸ¤–")
st.title("ğŸ¤– ë¬¸ë²• êµì • ì±—ë´‡")
st.caption("ë‚˜ëŠ” ë¬¸ë²•ì„ ë§ˆìŠ¤í„°í•œ ì´ˆë“±í•™ìƒì´ì•¼! ë­ë“ ì§€ ë¬¼ì–´ë´!")

if not API_KEY or API_KEY == "ì—¬ê¸°ì— ì‹¤ì œ êµ¬ê¸€ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”":
    st.error("ì•—! êµ¬ê¸€ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ì–´ìš”. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ì²˜ë¦¬í•˜ëŠ” ì œë„ˆë ˆì´í„° í•¨ìˆ˜
def stream_gemini_response(payload):
    """Gemini APIë¡œë¶€í„° ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ë°›ì•„ í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ yieldí•©ë‹ˆë‹¤."""
    last_error = None
    for api_version, model_name in API_CONFIGS:
        # ìŠ¤íŠ¸ë¦¬ë°ì„ ì§€ì›í•˜ëŠ” streamGenerateContent ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
        api_url = f"https://generativelanguage.googleapis.com/{api_version}/models/{model_name}:streamGenerateContent"
        params = {"key": API_KEY, "alt": "sse"}
        
        try:
            # stream=Trueë¡œ ìš”ì²­ì„ ë³´ë‚´ê³ , ì‘ë‹µì„ ìˆœíšŒí•©ë‹ˆë‹¤.
            with requests.post(api_url, params=params, headers={"Content-Type": "application/json"}, json=payload, stream=True, timeout=60) as response:
                response.raise_for_status()
                for chunk in response.iter_lines():
                    if chunk:
                        decoded_chunk = chunk.decode('utf-8')
                        if decoded_chunk.startswith('data: '):
                            try:
                                data = json.loads(decoded_chunk[6:])
                                if "candidates" in data and len(data["candidates"]) > 0:
                                    candidate = data["candidates"][0]
                                    if "content" in candidate and "parts" in candidate["content"]:
                                        yield candidate["content"]["parts"][0]["text"]
                            except json.JSONDecodeError:
                                continue # ê°€ë” ë¹ˆ data ì²­í¬ë‚˜ ì˜ëª»ëœ JSONì´ ì˜¬ ìˆ˜ ìˆìŒ
                return # ì„±ê³µì ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°ì´ ëë‚˜ë©´ í•¨ìˆ˜ ì¢…ë£Œ
        except requests.exceptions.HTTPError as e:
            last_error = e
            if e.response.status_code == 404:
                continue # 404 ì˜¤ë¥˜ ì‹œ ë‹¤ìŒ ëª¨ë¸ ì‹œë„
            else:
                break # ë‹¤ë¥¸ HTTP ì˜¤ë¥˜ëŠ” ì¦‰ì‹œ ì¤‘ë‹¨
        except Exception as exc:
            last_error = exc
            break
    
    # ëª¨ë“  ì‹œë„ê°€ ì‹¤íŒ¨í•œ ê²½ìš°
    if last_error:
        yield f"Geminië¥¼ í˜¸ì¶œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆì–´ìš”: {last_error}"


# ì„¸ì…˜ ìƒíƒœì— ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì´ì „ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ì„ ìœ„í•œ ì±„íŒ… ì…ë ¥ì°½
if prompt := st.chat_input("ë§ì¶¤ë²•ì´ë‚˜ ë¬¸ë²•ì´ ê¶ê¸ˆí•œ ë¬¸ì¥ì„ ì…ë ¥í•´ë´!"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•˜ê³  í™”ë©´ì— í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Gemini ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("Geminiê°€ ì—´ì‹¬íˆ ìƒê°í•˜ê³  ìˆì–´..."):
            # í˜ë¥´ì†Œë‚˜ ì„¤ì • ë° ëŒ€í™” ê¸°ë¡ì„ API ìš”ì²­ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            conversation_history = []
            for msg in st.session_state.messages:
                role = "model" if msg["role"] == "assistant" else "user"
                conversation_history.append({"role": role, "parts": [{"text": msg["content"]}]})

            # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ ì•ì— í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
            # ì°¸ê³ : GeminiëŠ” ê³µì‹ì ì¸ 'system' ì—­í• ì´ ì—†ìœ¼ë¯€ë¡œ, ëŒ€í™”ì˜ ì¼ë¶€ë¡œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
            system_prompt = (
                "ë„ˆëŠ” ë¬¸ë²•ì„ ì™„ë²½í•˜ê²Œ ë§ˆìŠ¤í„°í•œ ë˜‘ë˜‘í•œ ì´ˆë“±í•™ìƒì´ì•¼. "
                "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´, ë§ì¶¤ë²•ê³¼ ë¬¸ë²•ì„ ì¹œì ˆí•˜ê³  ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ì¤˜. "
                "í•­ìƒ ë°ê³  ëª…ë‘í•œ ì´ˆë“±í•™ìƒ ë§íˆ¬ë¥¼ ì‚¬ìš©í•´ì¤˜. ì˜ˆë¥¼ ë“¤ì–´, '~í–ˆì–´!', '~ì•¼!', '~ê±°ë“ !' ê°™ì€ ë§íˆ¬ë¥¼ ì‚¬ìš©í•´ë´."
            )
            
            # API ìš”ì²­ í˜ì´ë¡œë“œ êµ¬ì„±
            payload = {
                "contents": [
                    {"role": "user", "parts": [{"text": system_prompt}]},
                    {"role": "model", "parts": [{"text": "ì‘, ì•Œê² ì–´! ì´ì œë¶€í„° ë‚˜ëŠ” ë¬¸ë²•ì„ ë§ˆìŠ¤í„°í•œ ì´ˆë“±í•™ìƒì´ì•¼! ë­ë“ ì§€ ë¬¼ì–´ë´!"}]},
                    *conversation_history
                ],
                "generationConfig": {
                    "temperature": 0.7,
                    "topP": 1,
                    "topK": 1,
                },
                "safetySettings": [
                    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                ],
            }

            try:
                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ í™”ë©´ì— í‘œì‹œí•˜ê³  ì „ì²´ ì‘ë‹µì„ ì €ì¥
                response_stream = stream_gemini_response(payload)
                full_response = st.write_stream(response_stream)
                
                # ì„±ê³µì ìœ¼ë¡œ ì‘ë‹µì„ ë°›ìœ¼ë©´ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
                if full_response:
                     st.session_state.messages.append({"role": "assistant", "content": full_response})
                else:
                    # ìŠ¤íŠ¸ë¦¼ì—ì„œ ì•„ë¬´ê²ƒë„ ë°˜í™˜ë˜ì§€ ì•Šì€ ê²½ìš° (ì˜¤ë¥˜ëŠ” ìŠ¤íŠ¸ë¦¼ ë‚´ì—ì„œ ì²˜ë¦¬ë¨)
                    st.error("ì•—, ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆì–´. ë‹¤ì‹œ ì‹œë„í•´ì¤„ë˜?")
                    st.session_state.messages.pop() # ì‹¤íŒ¨í•œ ì‚¬ìš©ì ë©”ì‹œì§€ ì œê±°
            except Exception as e:
                error_message = f"ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {e}"
                st.error(error_message)
                # ì‹¤íŒ¨í•œ ê²½ìš°, ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ê¸°ë¡ì—ì„œ ì œê±°í•˜ì—¬ ì¬ì‹œë„í•  ìˆ˜ ìˆë„ë¡ í•¨
                st.session_state.messages.pop()
            else:
                # ìŠ¤íŠ¸ë¦¼ì—ì„œ ì•„ë¬´ê²ƒë„ ë°˜í™˜ë˜ì§€ ì•Šì€ ê²½ìš° (ì˜¤ë¥˜ëŠ” ìŠ¤íŠ¸ë¦¼ ë‚´ì—ì„œ ì²˜ë¦¬ë¨)
                st.error("ì•—, ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆì–´. ë‹¤ì‹œ ì‹œë„í•´ì¤„ë˜?")
                st.session_state.messages.pop() # ì‹¤íŒ¨í•œ ì‚¬ìš©ì ë©”ì‹œì§€ ì œê±°
        except Exception as e:
            error_message = f"ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {e}"
            st.error(error_message)
            # ì‹¤íŒ¨í•œ ê²½ìš°, ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ê¸°ë¡ì—ì„œ ì œê±°í•˜ì—¬ ì¬ì‹œë„í•  ìˆ˜ ìˆë„ë¡ í•¨
            st.session_state.messages.pop()
